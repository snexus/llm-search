# This file contains a configuration section relevant to LLM, not the entire config

llm:
  type: openai
  params:
    prompt_template: |
       Contex information is provided below. Given only the context and not prior knowledge, provide detailed answer to the question and references to the provided context. If answer isn't in the context, say you don't know.
       When answering questions, take into consideration the history of the chat converastion, which is listed below under Chat History. The chat history is in reverse chronological order, so the most recent exhange is at the top.
        
         ### Context:
         ---------------------
         {context}
         ---------------------

         ### Question: {question}
    model_kwargs:
      temperature: 0.0
      model_name: gpt-4o-mini